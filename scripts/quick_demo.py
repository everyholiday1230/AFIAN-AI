"""
Quick Demo - ë¹ ë¥¸ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

ëª©ì : 1ì¼ì¹˜ ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ë‚´ìš©:
1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (1ì¼)
2. ë°ì´í„° ì „ì²˜ë¦¬
3. í”¼ì²˜ ìƒì„±
4. ê°„ë‹¨í•œ ë°±í…ŒìŠ¤íŒ…

ì‚¬ìš©ë²•:
    python scripts/quick_demo.py
"""

import os
import sys
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class QuickDemo:
    """ë¹ ë¥¸ ë°ëª¨ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.demo_dir = self.project_root / "data" / "demo"
        self.demo_dir.mkdir(parents=True, exist_ok=True)
    
    def step1_download_data(self):
        """Step 1: 1ì¼ì¹˜ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        logger.info("="*60)
        logger.info("STEP 1: Downloading 1-day data")
        logger.info("="*60)
        
        # ì–´ì œ ë‚ ì§œ
        yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        today = datetime.now().strftime('%Y-%m-%d')
        
        cmd = [
            "python", "scripts/download_historical_data.py",
            "--symbols", "BTCUSDT",
            "--start-date", yesterday,
            "--end-date", today,
            "--interval", "1m",
            "--output-dir", str(self.demo_dir / "raw")
        ]
        
        result = subprocess.run(cmd, cwd=self.project_root)
        
        if result.returncode != 0:
            logger.error("âŒ Data download failed")
            return False
        
        logger.info("âœ… Data download completed")
        return True
    
    def step2_preprocess(self):
        """Step 2: ë°ì´í„° ì „ì²˜ë¦¬"""
        logger.info("="*60)
        logger.info("STEP 2: Preprocessing data")
        logger.info("="*60)
        
        cmd = [
            "python", "scripts/preprocess_data.py",
            "--input-dir", str(self.demo_dir / "raw"),
            "--output-dir", str(self.demo_dir / "processed"),
            "--clean-outliers",
            "--fill-missing",
            "--add-features"
        ]
        
        result = subprocess.run(cmd, cwd=self.project_root)
        
        if result.returncode != 0:
            logger.error("âŒ Preprocessing failed")
            return False
        
        logger.info("âœ… Preprocessing completed")
        return True
    
    def step3_generate_features(self):
        """Step 3: í”¼ì²˜ ìƒì„±"""
        logger.info("="*60)
        logger.info("STEP 3: Generating features")
        logger.info("="*60)
        
        cmd = [
            "python", "scripts/generate_features.py",
            "--input-dir", str(self.demo_dir / "processed"),
            "--output-dir", str(self.demo_dir / "features"),
            "--all-features"
        ]
        
        result = subprocess.run(cmd, cwd=self.project_root)
        
        if result.returncode != 0:
            logger.error("âŒ Feature generation failed")
            return False
        
        logger.info("âœ… Feature generation completed")
        return True
    
    def step4_summary(self):
        """Step 4: ê²°ê³¼ ìš”ì•½"""
        logger.info("="*60)
        logger.info("STEP 4: Summary")
        logger.info("="*60)
        
        # ìƒì„±ëœ íŒŒì¼ í™•ì¸
        raw_files = list((self.demo_dir / "raw").glob("*.parquet"))
        processed_files = list((self.demo_dir / "processed").glob("*.parquet"))
        feature_files = list((self.demo_dir / "features").glob("*.parquet"))
        
        logger.info(f"Raw data files: {len(raw_files)}")
        logger.info(f"Processed files: {len(processed_files)}")
        logger.info(f"Feature files: {len(feature_files)}")
        
        if feature_files:
            import pandas as pd
            
            # í”¼ì²˜ íŒŒì¼ ë¡œë“œ
            df = pd.read_parquet(feature_files[0])
            
            logger.info(f"\nğŸ“Š Feature Data Info:")
            logger.info(f"   - Rows: {len(df):,}")
            logger.info(f"   - Columns: {len(df.columns)}")
            logger.info(f"   - Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
            logger.info(f"\n   - Sample columns:")
            for i, col in enumerate(df.columns[:10], 1):
                logger.info(f"     {i}. {col}")
            logger.info(f"     ... and {len(df.columns) - 10} more")
        
        logger.info("\nâœ… Quick demo completed successfully!")
        logger.info(f"\nğŸ“ Demo data saved in: {self.demo_dir}")
        
        return True
    
    def run(self):
        """ì „ì²´ ë°ëª¨ ì‹¤í–‰"""
        logger.info("\n" + "="*60)
        logger.info("ğŸš€ QUANTUM ALPHA - Quick Demo")
        logger.info("="*60)
        logger.info("\nThis will test the entire pipeline with 1-day data")
        logger.info("Estimated time: 3-5 minutes\n")
        
        # Step 1: ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        if not self.step1_download_data():
            logger.error("Demo failed at step 1")
            return
        
        # Step 2: ì „ì²˜ë¦¬
        if not self.step2_preprocess():
            logger.error("Demo failed at step 2")
            return
        
        # Step 3: í”¼ì²˜ ìƒì„±
        if not self.step3_generate_features():
            logger.error("Demo failed at step 3")
            return
        
        # Step 4: ìš”ì•½
        self.step4_summary()
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ Next Steps:")
        logger.info("="*60)
        logger.info("1. Review generated features in data/demo/features/")
        logger.info("2. Start full 5-year data download: python scripts/download_historical_data.py")
        logger.info("3. Train AI models: python ai/training/pipelines/tft_training_pipeline.py")
        logger.info("4. See docs/NEXT_STEPS.md for complete guide")


def main():
    demo = QuickDemo()
    demo.run()


if __name__ == "__main__":
    main()
